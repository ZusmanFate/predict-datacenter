# ğŸš€ å®Œæ•´è¿è¡ŒæŒ‡å— - ä»é›¶å¼€å§‹

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨**ä¸€æ­¥æ­¥è¿è¡Œå’Œç†Ÿæ‚‰ç³»ç»Ÿ**ï¼ŒåŒ…æ‹¬ Impala æ•°æ®åº“è¿æ¥ã€Feast ç‰¹å¾å­˜å‚¨å’Œ Airflow å®šæ—¶ä»»åŠ¡ã€‚

---

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒå‡†å¤‡](#1-ç¯å¢ƒå‡†å¤‡)
2. [æµ‹è¯•æ•°æ®åº“è¿æ¥](#2-æµ‹è¯•æ•°æ®åº“è¿æ¥)
3. [è¿è¡Œç¤ºä¾‹ä»£ç ](#3-è¿è¡Œç¤ºä¾‹ä»£ç )
4. [ä½¿ç”¨ Feast ç‰¹å¾å­˜å‚¨](#4-ä½¿ç”¨-feast-ç‰¹å¾å­˜å‚¨)
5. [é…ç½® Airflow å®šæ—¶ä»»åŠ¡](#5-é…ç½®-airflow-å®šæ—¶ä»»åŠ¡)
6. [è®­ç»ƒå’Œé¢„æµ‹](#6-è®­ç»ƒå’Œé¢„æµ‹)
7. [API æœåŠ¡ä½¿ç”¨](#7-api-æœåŠ¡ä½¿ç”¨)
8. [å¸¸è§é—®é¢˜](#8-å¸¸è§é—®é¢˜)

---

## 1ï¸âƒ£ ç¯å¢ƒå‡†å¤‡

### æ­¥éª¤ 1.1: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# Windows PowerShell
python -m venv venv
.\venv\Scripts\activate

# éªŒè¯æ¿€æ´»
python --version
```

### æ­¥éª¤ 1.2: å®‰è£…ä¾èµ–

```bash
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install -r requirements.txt

# å¦‚æœå®‰è£…è¾ƒæ…¢ï¼Œä½¿ç”¨å›½å†…é•œåƒ
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

**æ³¨æ„**ï¼šå¦‚æœ `impyla` æˆ– `apache-airflow` å®‰è£…å¤±è´¥ï¼Œå¯ä»¥å…ˆè·³è¿‡ï¼š

```bash
# æœ€å°åŒ–å®‰è£…ï¼ˆä¸åŒ…å« Airflowï¼‰
pip install numpy pandas scikit-learn lightgbm sqlalchemy pymysql impyla fastapi uvicorn mlflow pyyaml loguru tqdm matplotlib seaborn
```

---

## 2ï¸âƒ£ æµ‹è¯•æ•°æ®åº“è¿æ¥

### æ­¥éª¤ 2.1: éªŒè¯é…ç½®

æ£€æŸ¥ `config/database.yaml` çš„ Impala é…ç½®ï¼š

```yaml
# Impala é…ç½®
impala:
  host: "172.17.224.214"
  port: 21050
  database: "Impala"
  username: ""
  password: ""
  auth_mechanism: "NOSASL"
  echo: false
```

### æ­¥éª¤ 2.2: æµ‹è¯•è¿æ¥

åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_connection.py`ï¼š

```python
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

from src.data.database import get_db_manager
from src.utils.logger import get_logger

logger = get_logger(__name__)

def test_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        logger.info("=" * 60)
        logger.info("æµ‹è¯• Impala æ•°æ®åº“è¿æ¥...")
        logger.info("=" * 60)
        
        # è·å–æ•°æ®åº“ç®¡ç†å™¨
        db_manager = get_db_manager()
        
        # æµ‹è¯•ç®€å•æŸ¥è¯¢
        test_query = "SELECT 1 as test"
        result = db_manager.execute_query(test_query)
        
        logger.info(f"âœ“ è¿æ¥æˆåŠŸï¼æŸ¥è¯¢ç»“æœ: {result}")
        
        # æµ‹è¯•é”€é‡è¡¨
        sales_table = db_manager.config['tables']['sales']['name']
        count_query = f"SELECT COUNT(*) as cnt FROM {sales_table} LIMIT 1"
        
        try:
            result = db_manager.execute_query(count_query)
            logger.info(f"âœ“ é”€é‡è¡¨è®¿é—®æˆåŠŸ: {sales_table}")
        except Exception as e:
            logger.warning(f"âš  é”€é‡è¡¨æŸ¥è¯¢å¤±è´¥: {e}")
        
        logger.info("=" * 60)
        logger.info("âœ… æ•°æ®åº“è¿æ¥æµ‹è¯•å®Œæˆï¼")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ è¿æ¥å¤±è´¥: {e}", exc_info=True)
        return False
    
    return True

if __name__ == "__main__":
    success = test_connection()
    sys.exit(0 if success else 1)
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
python test_connection.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
[INFO] æµ‹è¯• Impala æ•°æ®åº“è¿æ¥...
[INFO] âœ“ è¿æ¥æˆåŠŸï¼
[INFO] âœ“ é”€é‡è¡¨è®¿é—®æˆåŠŸ: dwd.dwd_erp_mst_biz_all_df
[INFO] âœ… æ•°æ®åº“è¿æ¥æµ‹è¯•å®Œæˆï¼
```

---

## 3ï¸âƒ£ è¿è¡Œç¤ºä¾‹ä»£ç 

### æ­¥éª¤ 3.1: åŠ è½½å°‘é‡æ•°æ®æµ‹è¯•

åˆ›å»º `test_data_loading.py`ï¼š

```python
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

from src.data.loader import DataLoader
from src.utils.logger import get_logger

logger = get_logger(__name__)

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    try:
        logger.info("=" * 60)
        logger.info("æµ‹è¯•æ•°æ®åŠ è½½...")
        logger.info("=" * 60)
        
        loader = DataLoader()
        
        # è·å–å”¯ä¸€çš„è¯å“å’ŒåŒ»é™¢åˆ—è¡¨
        logger.info("1. è·å–è¯å“å’ŒåŒ»é™¢åˆ—è¡¨...")
        gcodes = loader.get_unique_gcodes()
        logger.info(f"   âœ“ æ‰¾åˆ° {len(gcodes)} ä¸ªå”¯ä¸€è¯å“")
        logger.info(f"   å‰5ä¸ªè¯å“: {gcodes[:5]}")
        
        cust_names = loader.get_unique_hospitals()
        logger.info(f"   âœ“ æ‰¾åˆ° {len(cust_names)} ä¸ªå”¯ä¸€å®¢æˆ·")
        logger.info(f"   å‰5ä¸ªå®¢æˆ·: {cust_names[:5]}")
        
        # åŠ è½½å•ä¸ªè¯å“-åŒ»é™¢çš„æ•°æ®
        if gcodes and cust_names:
            logger.info("\n2. åŠ è½½ç¤ºä¾‹æ•°æ®...")
            gcode = gcodes[0]
            cust_name = cust_names[0]
            
            logger.info(f"   è¯å“: {gcode}")
            logger.info(f"   å®¢æˆ·: {cust_name}")
            
            df = loader.load_sales_data(
                gcode=gcode,
                cust_name=cust_name,
                limit=100  # åªåŠ è½½100æ¡æµ‹è¯•
            )
            
            logger.info(f"   âœ“ æˆåŠŸåŠ è½½ {len(df)} æ¡æ•°æ®")
            logger.info(f"   æ•°æ®åˆ—: {df.columns.tolist()}")
            
            if len(df) > 0:
                logger.info(f"   æ—¥æœŸèŒƒå›´: {df['create_dt'].min()} åˆ° {df['create_dt'].max()}")
                logger.info(f"   å¹³å‡é”€é‡: {df['qty'].mean():.2f}")
            
            logger.info("\næ•°æ®æ ·æœ¬:")
            print(df.head())
        
        logger.info("\n=" * 60)
        logger.info("âœ… æ•°æ®åŠ è½½æµ‹è¯•å®Œæˆï¼")
        logger.info("=" * 60)
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False

if __name__ == "__main__":
    success = test_data_loading()
    sys.exit(0 if success else 1)
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
python test_data_loading.py
```

### æ­¥éª¤ 3.2: è¿è¡Œå®Œæ•´ç¤ºä¾‹ï¼ˆéœ€è¦è°ƒæ•´ï¼‰

ç”±äºæ‚¨çš„æ•°æ®ç»“æ„ä¸åŸå§‹ç¤ºä¾‹ä¸åŒï¼Œéœ€è¦åˆ›å»ºé€‚é…çš„ç¤ºä¾‹ï¼š

åˆ›å»º `examples/impala_example.py`ï¼š

```python
"""
Impala æ•°æ®åº“å®Œæ•´ç¤ºä¾‹
æ¼”ç¤ºä» Impala åŠ è½½æ•°æ®åˆ°æ¨¡å‹è®­ç»ƒçš„å®Œæ•´æµç¨‹
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from src.data.loader import DataLoader
from src.data.processor import DataProcessor
from src.features.builder import FeatureBuilder
from src.models.lgb_model import LightGBMModel
from src.training.trainer import ModelTrainer
from src.training.evaluator import ModelEvaluator
from src.utils.logger import get_logger

logger = get_logger(__name__)


def main():
    """å®Œæ•´ç¤ºä¾‹"""
    
    print("=" * 80)
    print("è¯å“é”€é‡é¢„æµ‹ç³»ç»Ÿ - Impala æ•°æ®åº“ç¤ºä¾‹")
    print("=" * 80)
    
    try:
        # ==================== æ­¥éª¤ 1: é€‰æ‹©æ•°æ® ====================
        print("\n[æ­¥éª¤ 1/6] é€‰æ‹©è¯å“å’Œå®¢æˆ·...")
        loader = DataLoader()
        
        # è·å–è¯å“å’Œå®¢æˆ·åˆ—è¡¨
        gcodes = loader.get_unique_gcodes()
        cust_names = loader.get_unique_hospitals()
        
        if not gcodes or not cust_names:
            logger.error("æœªæ‰¾åˆ°è¯å“æˆ–å®¢æˆ·æ•°æ®")
            return
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªè¯å“å’Œå®¢æˆ·ä½œä¸ºç¤ºä¾‹
        GCODE = gcodes[0]
        CUST_NAME = cust_names[0]
        
        print(f"âœ“ é€‰æ‹©è¯å“: {GCODE}")
        print(f"âœ“ é€‰æ‹©å®¢æˆ·: {CUST_NAME}")
        
        # ==================== æ­¥éª¤ 2: åŠ è½½æ•°æ® ====================
        print("\n[æ­¥éª¤ 2/6] åŠ è½½é”€é‡æ•°æ®...")
        
        df = loader.load_sales_data(
            gcode=GCODE,
            cust_name=CUST_NAME,
            limit=1000  # é™åˆ¶æ•°æ®é‡ç”¨äºæµ‹è¯•
        )
        
        if len(df) < 50:
            logger.error(f"æ•°æ®é‡ä¸è¶³: {len(df)} æ¡")
            return
        
        print(f"âœ“ åŠ è½½äº† {len(df)} æ¡é”€é‡è®°å½•")
        print(f"  æ—¥æœŸèŒƒå›´: {df['create_dt'].min()} åˆ° {df['create_dt'].max()}")
        print(f"  å¹³å‡é”€é‡: {df['qty'].mean():.2f}")
        
        # ==================== æ­¥éª¤ 3: æ•°æ®é¢„å¤„ç† ====================
        print("\n[æ­¥éª¤ 3/6] æ•°æ®é¢„å¤„ç†...")
        processor = DataProcessor()
        
        # é‡å‘½ååˆ—ä»¥é€‚é…é¢„å¤„ç†å™¨
        df_processed = df.rename(columns={
            'create_dt': 'date',
            'qty': 'sales_quantity',
            'gcode': 'drug_id',
            'cust_name': 'hospital_id'
        })
        
        # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®é›†
        df_processed = processor.create_time_series_dataset(
            df_processed,
            drug_id=GCODE,
            hospital_id=CUST_NAME,
            date_column='date',
            target_column='sales_quantity'
        )
        
        # å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
        df_processed = processor.handle_missing_values(df_processed, method='forward_fill')
        df_processed = processor.handle_outliers(df_processed, 'sales_quantity', method='iqr')
        
        print(f"âœ“ é¢„å¤„ç†å®Œæˆï¼Œæ•°æ®é‡: {len(df_processed)}")
        
        # ==================== æ­¥éª¤ 4: ç‰¹å¾å·¥ç¨‹ ====================
        print("\n[æ­¥éª¤ 4/6] ç‰¹å¾å·¥ç¨‹...")
        feature_builder = FeatureBuilder()
        df_features = feature_builder.build_features(
            df_processed,
            target_column='sales_quantity',
            date_column='date'
        )
        
        print(f"âœ“ æ„å»ºäº† {len(df_features.columns)} ä¸ªç‰¹å¾")
        print(f"  ç‰¹å¾æ•°é‡: {len(df_features)}")
        
        # ==================== æ­¥éª¤ 5: è®­ç»ƒæ¨¡å‹ ====================
        print("\n[æ­¥éª¤ 5/6] è®­ç»ƒæ¨¡å‹...")
        
        model = LightGBMModel()
        trainer = ModelTrainer(model, experiment_name="impala_example")
        
        trained_model, test_metrics = trainer.train_on_full_data(
            df_features,
            target_column='sales_quantity',
            test_size=0.2,
            log_mlflow=False
        )
        
        print("âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"  RMSE: {test_metrics['rmse']:.4f}")
        print(f"  MAE: {test_metrics['mae']:.4f}")
        print(f"  MAPE: {test_metrics['mape']:.4f}%")
        print(f"  RÂ²: {test_metrics['r2']:.4f}")
        
        # ==================== æ­¥éª¤ 6: ç‰¹å¾é‡è¦æ€§ ====================
        print("\n[æ­¥éª¤ 6/6] ç‰¹å¾é‡è¦æ€§åˆ†æ...")
        
        importance_df = trained_model.get_feature_importance()
        
        print("âœ“ Top 10 é‡è¦ç‰¹å¾:")
        for idx, row in importance_df.head(10).iterrows():
            print(f"  {idx+1}. {row['feature']}: {row['importance']:.2f}")
        
        # ==================== ä¿å­˜æ¨¡å‹ ====================
        model_path = f"models/impala_example_{GCODE}_{CUST_NAME}.txt"
        trained_model.save(model_path)
        print(f"\nâœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        
        # ==================== å®Œæˆ ====================
        print("\n" + "=" * 80)
        print("âœ… ç¤ºä¾‹è¿è¡ŒæˆåŠŸå®Œæˆï¼")
        print("=" * 80)
        
        print("\nä¸‹ä¸€æ­¥å»ºè®®:")
        print("  1. å°è¯•å…¶ä»–è¯å“å’Œå®¢æˆ·ç»„åˆ")
        print("  2. è°ƒæ•´ç‰¹å¾å·¥ç¨‹å‚æ•°: config/config.yaml")
        print("  3. å¯åŠ¨ API æœåŠ¡: uvicorn src.serving.api:app --reload")
        print("  4. é…ç½® Feast ç‰¹å¾å­˜å‚¨")
        print("  5. è®¾ç½® Airflow å®šæ—¶ä»»åŠ¡")
        
    except Exception as e:
        logger.error(f"ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}", exc_info=True)
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
```

è¿è¡Œç¤ºä¾‹ï¼š

```bash
python examples/impala_example.py
```

---

## 4ï¸âƒ£ ä½¿ç”¨ Feast ç‰¹å¾å­˜å‚¨

### æ­¥éª¤ 4.1: åˆå§‹åŒ– Feast ä»“åº“

```bash
cd feature_store

# åˆå§‹åŒ– Feastï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
feast init

# åº”ç”¨ç‰¹å¾å®šä¹‰
feast apply
```

### æ­¥éª¤ 4.2: å‡†å¤‡ç‰¹å¾æ•°æ®

åˆ›å»º `scripts/prepare_feast_features.py`ï¼š

```python
"""
å‡†å¤‡ç‰¹å¾æ•°æ®å¹¶å¯¼å…¥ Feast
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from src.data.loader import DataLoader
from src.features.builder import FeatureBuilder
from src.features.store import FeatureStore, prepare_features_for_feast
from src.utils.logger import get_logger

logger = get_logger(__name__)

def main():
    logger.info("å‡†å¤‡ Feast ç‰¹å¾æ•°æ®...")
    
    # åŠ è½½æ•°æ®
    loader = DataLoader()
    gcodes = loader.get_unique_gcodes()[:5]  # å‰5ä¸ªè¯å“
    
    # æ„å»ºç‰¹å¾
    feature_builder = FeatureBuilder()
    
    all_features = []
    for gcode in gcodes:
        df = loader.load_sales_data(gcode=gcode, limit=1000)
        df_features = feature_builder.build_features(df)
        all_features.append(df_features)
    
    # åˆå¹¶æ‰€æœ‰ç‰¹å¾
    import pandas as pd
    df_all = pd.concat(all_features, ignore_index=True)
    
    # å‡†å¤‡ Feast æ ¼å¼
    df_feast = prepare_features_for_feast(df_all)
    
    # ä¿å­˜åˆ° Parquet
    output_path = "data/features/sales_features.parquet"
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    df_feast.to_parquet(output_path)
    
    logger.info(f"âœ“ ç‰¹å¾æ•°æ®å·²ä¿å­˜: {output_path}")
    
    # ç‰©åŒ–åˆ° Feast
    store = FeatureStore()
    store.materialize_features(
        start_date="2024-01-01",
        end_date="2024-12-31"
    )
    
    logger.info("âœ“ ç‰¹å¾å·²ç‰©åŒ–åˆ° Feast")

if __name__ == "__main__":
    main()
```

### æ­¥éª¤ 4.3: ä» Feast è·å–ç‰¹å¾

```python
from src.features.store import FeatureStore

store = FeatureStore()

# åœ¨çº¿ç‰¹å¾ï¼ˆç”¨äºå®æ—¶é¢„æµ‹ï¼‰
entity_rows = [
    {"gcode": "D001", "cust_name": "Hospital_A"}
]
features = [
    "sales_features:sales_quantity_lag_1",
    "sales_features:sales_quantity_rolling_7_mean"
]
online_features = store.get_online_features(entity_rows, features)
```

---

## 5ï¸âƒ£ é…ç½® Airflow å®šæ—¶ä»»åŠ¡

### æ­¥éª¤ 5.1: åˆå§‹åŒ– Airflow

```bash
# è®¾ç½® Airflow Home
export AIRFLOW_HOME=~/airflow  # Linux/Mac
$env:AIRFLOW_HOME = "$HOME\airflow"  # Windows PowerShell

# åˆå§‹åŒ–æ•°æ®åº“
airflow db init

# åˆ›å»ºç®¡ç†å‘˜ç”¨æˆ·
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com \
    --password admin
```

### æ­¥éª¤ 5.2: é…ç½® DAG è·¯å¾„

ç¼–è¾‘ `$AIRFLOW_HOME/airflow.cfg`ï¼š

```ini
[core]
dags_folder = D:\é¢„æµ‹æ¨¡å‹å·¥ç¨‹\airflow\dags
```

æˆ–è€…åˆ›å»ºç¬¦å·é“¾æ¥ï¼š

```bash
# Windows (ä»¥ç®¡ç†å‘˜è¿è¡Œ)
mklink /D %AIRFLOW_HOME%\dags D:\é¢„æµ‹æ¨¡å‹å·¥ç¨‹\airflow\dags
```

### æ­¥éª¤ 5.3: å¯åŠ¨ Airflow

```bash
# å¯åŠ¨ Web æœåŠ¡å™¨
airflow webserver --port 8080

# æ–°å¼€ç»ˆç«¯ï¼Œå¯åŠ¨è°ƒåº¦å™¨
airflow scheduler
```

è®¿é—® Airflow UIï¼šhttp://localhost:8080

### æ­¥éª¤ 5.4: å¯ç”¨ DAG

åœ¨ Airflow UI ä¸­ï¼š
1. æ‰¾åˆ° `drug_sales_forecast_daily` DAG
2. ç‚¹å‡»å¼€å…³å¯ç”¨
3. ç‚¹å‡» "Trigger DAG" æ‰‹åŠ¨è§¦å‘

---

## 6ï¸âƒ£ è®­ç»ƒå’Œé¢„æµ‹

### å•æ¨¡å‹è®­ç»ƒ

```bash
# ä½¿ç”¨æ–°çš„å‚æ•°å
python scripts/train.py --gcode D001 --cust_name "Hospital_A"

# æˆ–ä½¿ç”¨æ—§çš„å‚æ•°åï¼ˆå‘åå…¼å®¹ï¼‰
python scripts/train.py --drug_id D001 --hospital_id H001
```

### æ‰¹é‡è®­ç»ƒ

```bash
python scripts/batch_train.py --max_workers 4
```

### é¢„æµ‹

```bash
python scripts/predict.py \
  --model_path models/lightgbm_D001_H001.txt \
  --gcode D001 \
  --cust_name "Hospital_A" \
  --output predictions.csv
```

---

## 7ï¸âƒ£ API æœåŠ¡ä½¿ç”¨

### å¯åŠ¨ API

```bash
uvicorn src.serving.api:app --host 0.0.0.0 --port 8000 --reload
```

### API è°ƒç”¨ç¤ºä¾‹

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# è·å–è¯å“åˆ—è¡¨
curl http://localhost:8000/drugs

# é¢„æµ‹
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "drug_id": "D001",
    "hospital_id": "H001",
    "model_path": "models/lightgbm_D001_H001.txt"
  }'
```

è®¿é—® API æ–‡æ¡£ï¼šhttp://localhost:8000/docs

---

## 8ï¸âƒ£ å¸¸è§é—®é¢˜

### Q1: Impala è¿æ¥è¶…æ—¶

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping 172.17.224.214

# æ£€æŸ¥é˜²ç«å¢™
# ç¡®ä¿ç«¯å£ 21050 å¼€æ”¾
```

### Q2: ç‰¹å¾å·¥ç¨‹åæ•°æ®ä¸ºç©º

**åŸå› **ï¼šæ»åç‰¹å¾å¯¼è‡´å‰é¢çš„æ•°æ®è¢«åˆ é™¤

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# è°ƒæ•´æ»åæœŸé…ç½® config/config.yaml
features:
  lag_features: [1, 7, 30]  # å‡å°‘æ»åæœŸ
```

### Q3: å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# é™åˆ¶æ•°æ®é‡
df = loader.load_sales_data(gcode=gcode, limit=5000)

# æˆ–å‡å°‘ç‰¹å¾æ•°é‡
```

### Q4: Airflow DAG ä¸æ˜¾ç¤º

**æ£€æŸ¥æ­¥éª¤**ï¼š
1. ç¡®è®¤ DAG æ–‡ä»¶åœ¨æ­£ç¡®è·¯å¾„
2. æ£€æŸ¥ Python è¯­æ³•é”™è¯¯ï¼š`python airflow/dags/drug_sales_forecast_dag.py`
3. æŸ¥çœ‹ Airflow æ—¥å¿—

---

## ğŸ‰ æ­å–œï¼

æ‚¨ç°åœ¨å·²ç»ï¼š
- âœ… è¿æ¥åˆ° Impala æ•°æ®åº“
- âœ… è¿è¡Œäº†å®Œæ•´çš„é¢„æµ‹æµç¨‹
- âœ… äº†è§£äº† Feast ç‰¹å¾å­˜å‚¨
- âœ… é…ç½®äº† Airflow å®šæ—¶ä»»åŠ¡
- âœ… å¯åŠ¨äº† API æœåŠ¡

### ğŸ“š ä¸‹ä¸€æ­¥å­¦ä¹ 

1. **ä¼˜åŒ–ç‰¹å¾**ï¼šæ ¹æ®ä¸šåŠ¡çŸ¥è¯†è°ƒæ•´ç‰¹å¾å·¥ç¨‹
2. **æ¨¡å‹è°ƒä¼˜**ï¼šä½¿ç”¨ Optuna è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
3. **ç›‘æ§å‘Šè­¦**ï¼šé…ç½®æ•°æ®æ¼‚ç§»æ£€æµ‹
4. **æ‰©å±•æ¨¡å‹**ï¼šæ·»åŠ  XGBoostã€Prophet ç­‰æ¨¡å‹
5. **ç”Ÿäº§éƒ¨ç½²**ï¼šDocker å®¹å™¨åŒ–éƒ¨ç½²

### ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

- æŸ¥çœ‹æ—¥å¿—ï¼š`logs/app.log`
- API æ–‡æ¡£ï¼šhttp://localhost:8000/docs
- MLflow UIï¼š`mlflow ui`

ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼ğŸš€
