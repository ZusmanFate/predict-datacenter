"""
StarRocks æ•°æ®åº“å®Œæ•´ç¤ºä¾‹
æ¼”ç¤ºä» StarRocks åŠ è½½æ•°æ®åˆ°æ¨¡å‹è®­ç»ƒçš„å®Œæ•´æµç¨‹
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from src.data.loader import DataLoader
from src.data.processor import DataProcessor
from src.features.builder import FeatureBuilder
from src.models.lgb_model import LightGBMModel
from src.training.trainer import ModelTrainer
from src.training.evaluator import ModelEvaluator
from src.utils.logger import get_logger
import pandas as pd

logger = get_logger(__name__)


def main():
    """å®Œæ•´ç¤ºä¾‹"""
    
    print("=" * 80)
    print("è¯å“é”€é‡é¢„æµ‹ç³»ç»Ÿ - StarRocks æ•°æ®åº“ç¤ºä¾‹")
    print("=" * 80)
    
    try:
        # ==================== æ­¥éª¤ 1: é€‰æ‹©æ•°æ® ====================
        print("\n[æ­¥éª¤ 1/7] è·å–è¯å“å’Œå®¢æˆ·åˆ—è¡¨...")
        loader = DataLoader()
        
        # è·å–å”¯ä¸€çš„è¯å“å’Œå®¢æˆ·
        print("  æ­£åœ¨æŸ¥è¯¢è¯å“åˆ—è¡¨...")
        gcodes = loader.get_unique_gcodes()
        print(f"  âœ“ æ‰¾åˆ° {len(gcodes)} ä¸ªå”¯ä¸€è¯å“")
        
        print("  æ­£åœ¨æŸ¥è¯¢å®¢æˆ·åˆ—è¡¨...")
        cust_names = loader.get_unique_hospitals()
        print(f"  âœ“ æ‰¾åˆ° {len(cust_names)} ä¸ªå”¯ä¸€å®¢æˆ·")
        
        if not gcodes or not cust_names:
            logger.error("æœªæ‰¾åˆ°è¯å“æˆ–å®¢æˆ·æ•°æ®")
            return
        
        # è¿‡æ»¤æ‰ None å’Œç©ºå­—ç¬¦ä¸²ï¼Œé€‰æ‹©æœ‰æ•ˆçš„è¯å“å’Œå®¢æˆ·
        valid_gcodes = [g for g in gcodes if g and str(g).strip() and str(g) != 'None']
        valid_cust_names = [c for c in cust_names if c and str(c).strip() and str(c) != 'None']
        
        if not valid_gcodes or not valid_cust_names:
            logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¯å“æˆ–å®¢æˆ·æ•°æ®")
            return
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„è¯å“å’Œå®¢æˆ·ä½œä¸ºç¤ºä¾‹
        GCODE = valid_gcodes[0]
        CUST_NAME = valid_cust_names[0]
        
        print(f"\n  é€‰æ‹©ç¤ºä¾‹ç»„åˆ:")
        print(f"    è¯å“ç¼–ç : {GCODE}")
        print(f"    å®¢æˆ·åç§°: {CUST_NAME}")
        
        # ==================== æ­¥éª¤ 2: åŠ è½½æ•°æ® ====================
        print("\n[æ­¥éª¤ 2/7] åŠ è½½é”€é‡æ•°æ®...")
        
        # åŠ è½½æœ€è¿‘çš„æ•°æ®ï¼ˆé™åˆ¶æ•°é‡ç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
        df = loader.load_sales_data(
            gcode=GCODE,
            cust_name=CUST_NAME,
            limit=2000  # é™åˆ¶æ•°æ®é‡ç”¨äºå¿«é€Ÿæµ‹è¯•
        )
        
        if len(df) < 100:
            logger.error(f"æ•°æ®é‡ä¸è¶³: {len(df)} æ¡ï¼Œè‡³å°‘éœ€è¦ 100 æ¡")
            print(f"\n  âš  æ•°æ®é‡ä¸è¶³ï¼Œå°è¯•å…¶ä»–è¯å“-å®¢æˆ·ç»„åˆ...")
            
            # å°è¯•æ‰¾ä¸€ä¸ªæ•°æ®é‡è¶³å¤Ÿçš„ç»„åˆ
            for gcode in gcodes[:10]:
                for cust_name in cust_names[:5]:
                    df_test = loader.load_sales_data(
                        gcode=gcode,
                        cust_name=cust_name,
                        limit=2000
                    )
                    if len(df_test) >= 100:
                        GCODE = gcode
                        CUST_NAME = cust_name
                        df = df_test
                        print(f"  âœ“ æ‰¾åˆ°åˆé€‚çš„ç»„åˆ: {GCODE} - {CUST_NAME}")
                        break
                if len(df) >= 100:
                    break
            
            if len(df) < 100:
                logger.error("æœªæ‰¾åˆ°æ•°æ®é‡è¶³å¤Ÿçš„ç»„åˆ")
                return
        
        print(f"  âœ“ åŠ è½½äº† {len(df)} æ¡é”€é‡è®°å½•")
        print(f"  æ—¥æœŸèŒƒå›´: {df['create_dt'].min()} åˆ° {df['create_dt'].max()}")
        print(f"  å¹³å‡é”€é‡: {df['qty'].mean():.2f}")
        print(f"  æ€»é”€é‡: {df['qty'].sum():.0f}")
        
        # ==================== æ­¥éª¤ 3: æ•°æ®é¢„å¤„ç† ====================
        print("\n[æ­¥éª¤ 3/7] æ•°æ®é¢„å¤„ç†...")
        processor = DataProcessor()
        
        # é‡å‘½ååˆ—ä»¥é€‚é…é¢„å¤„ç†å™¨ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        df_processed = df.rename(columns={
            'create_dt': 'date',
            'qty': 'sales_quantity',
            'gcode': 'drug_id',
            'cust_name': 'hospital_id'
        })
        
        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯ datetime ç±»å‹
        df_processed['date'] = pd.to_datetime(df_processed['date'])
        
        # æŒ‰æ—¥æœŸæ’åº
        df_processed = df_processed.sort_values('date').reset_index(drop=True)
        
        # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®é›†
        df_processed = processor.create_time_series_dataset(
            df_processed,
            drug_id=GCODE,
            hospital_id=CUST_NAME,
            date_column='date',
            target_column='sales_quantity'
        )
        
        # å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
        df_processed = processor.handle_missing_values(df_processed, method='forward_fill')
        df_processed = processor.handle_outliers(
            df_processed, 
            'sales_quantity', 
            method='iqr',
            threshold=3.0
        )
        
        print(f"  âœ“ é¢„å¤„ç†å®Œæˆï¼Œæ•°æ®é‡: {len(df_processed)}")
        
        # ==================== æ­¥éª¤ 4: ç‰¹å¾å·¥ç¨‹ ====================
        print("\n[æ­¥éª¤ 4/7] ç‰¹å¾å·¥ç¨‹...")
        feature_builder = FeatureBuilder()
        df_features = feature_builder.build_features(
            df_processed,
            target_column='sales_quantity',
            date_column='date'
        )
        
        print(f"  âœ“ æ„å»ºäº† {len(df_features.columns)} ä¸ªç‰¹å¾")
        print(f"  ç‰¹å¾æ•°æ®é‡: {len(df_features)} æ¡")
        
        # è·å–ç‰¹å¾åˆ—ï¼ˆæ’é™¤ç›®æ ‡åˆ—å’Œæ—¥æœŸåˆ—ï¼‰
        feature_cols = [col for col in df_features.columns 
                       if col not in ['sales_quantity', 'date', 'drug_id', 'hospital_id']]
        print(f"  å¯ç”¨ç‰¹å¾: {len(feature_cols)} ä¸ª")
        
        if len(df_features) < 50:
            logger.error(f"ç‰¹å¾å·¥ç¨‹åæ•°æ®é‡ä¸è¶³: {len(df_features)} æ¡")
            return
        
        # ==================== æ­¥éª¤ 5: è®­ç»ƒæ¨¡å‹ ====================
        print("\n[æ­¥éª¤ 5/7] è®­ç»ƒæ¨¡å‹...")
        
        # åˆ›å»º LightGBM æ¨¡å‹
        model = LightGBMModel()
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = ModelTrainer(model, experiment_name="starrocks_example")
        
        # åœ¨å®Œæ•´æ•°æ®ä¸Šè®­ç»ƒ
        trained_model, test_metrics = trainer.train_on_full_data(
            df_features,
            target_column='sales_quantity',
            test_size=0.2,
            log_mlflow=False  # æš‚æ—¶ä¸è®°å½•åˆ° MLflow
        )
        
        print("  âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"    RMSE: {test_metrics['rmse']:.4f}")
        print(f"    MAE: {test_metrics['mae']:.4f}")
        print(f"    MAPE: {test_metrics['mape']:.4f}%")
        print(f"    RÂ²: {test_metrics['r2']:.4f}")
        
        # ==================== æ­¥éª¤ 6: æ¨¡å‹è¯„ä¼° ====================
        print("\n[æ­¥éª¤ 6/7] æ¨¡å‹è¯„ä¼°...")
        
        # è·å–æµ‹è¯•é›†
        split_idx = int(len(df_features) * 0.8)
        test_df = df_features.iloc[split_idx:]
        
        X_test = test_df[feature_cols]
        y_test = test_df['sales_quantity']
        
        # é¢„æµ‹
        y_pred = trained_model.predict(X_test)
        
        # è¯„ä¼°
        evaluator = ModelEvaluator()
        metrics = evaluator.evaluate(y_test.values, y_pred, return_details=True)
        
        print("  âœ“ è¯„ä¼°å®Œæˆ")
        for metric_name, metric_value in metrics.items():
            print(f"    {metric_name.upper()}: {metric_value:.4f}")
        
        # ==================== æ­¥éª¤ 7: ç‰¹å¾é‡è¦æ€§ ====================
        print("\n[æ­¥éª¤ 7/7] ç‰¹å¾é‡è¦æ€§åˆ†æ...")
        
        importance_df = trained_model.get_feature_importance()
        
        print("  âœ“ Top 10 é‡è¦ç‰¹å¾:")
        for idx, row in importance_df.head(10).iterrows():
            print(f"    {idx+1}. {row['feature']}: {row['importance']:.2f}")
        
        # ==================== ä¿å­˜æ¨¡å‹ ====================
        print("\n[å¯é€‰] ä¿å­˜æ¨¡å‹...")
        model_path = f"models/starrocks_{GCODE}_{CUST_NAME[:20]}.txt"
        Path(model_path).parent.mkdir(parents=True, exist_ok=True)
        trained_model.save(model_path)
        print(f"  âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        
        # ==================== å®Œæˆ ====================
        print("\n" + "=" * 80)
        print("âœ… ç¤ºä¾‹è¿è¡ŒæˆåŠŸå®Œæˆï¼")
        print("=" * 80)
        
        print("\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  è¯å“ç¼–ç : {GCODE}")
        print(f"  å®¢æˆ·åç§°: {CUST_NAME}")
        print(f"  è®­ç»ƒæ•°æ®: {len(df_features)} æ¡")
        print(f"  ç‰¹å¾æ•°é‡: {len(feature_cols)} ä¸ª")
        print(f"  æ¨¡å‹æ€§èƒ½: RMSE={test_metrics['rmse']:.2f}, RÂ²={test_metrics['r2']:.4f}")
        
        print("\nğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("  1. å°è¯•å…¶ä»–è¯å“å’Œå®¢æˆ·ç»„åˆ")
        print("  2. è°ƒæ•´ç‰¹å¾å·¥ç¨‹å‚æ•°: config/config.yaml")
        print("  3. æ‰¹é‡è®­ç»ƒå¤šä¸ªæ¨¡å‹: python scripts/batch_train.py")
        print("  4. å¯åŠ¨ API æœåŠ¡: uvicorn src.serving.api:app --reload")
        print("  5. è¶…å‚æ•°ä¼˜åŒ–: ä½¿ç”¨ HyperparameterOptimizer")
        
    except Exception as e:
        logger.error(f"ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}", exc_info=True)
        print(f"\nâŒ é”™è¯¯: {e}")
        print("\nè¯·æ£€æŸ¥:")
        print("  1. StarRocks è¿æ¥æ˜¯å¦æ­£å¸¸")
        print("  2. æ•°æ®è¡¨æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®")
        print("  3. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: logs/app.log")
        sys.exit(1)


if __name__ == "__main__":
    main()
