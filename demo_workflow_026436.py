"""
å®Œæ•´å·¥ä½œæµæ¼”ç¤º - ä½¿ç”¨ gcode=026436ï¼ˆä½Žé’™è…¹è†œé€æžæ¶²ï¼‰
å±•ç¤ºä»Žæ•°æ®åŠ è½½åˆ°æ¨¡åž‹è®­ç»ƒçš„å®Œæ•´æµç¨‹
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

from src.data.loader import DataLoader
from src.data.processor import DataProcessor
from src.features.builder import FeatureBuilder
from src.models.lgb_model import LightGBMModel
from src.training.trainer import ModelTrainer
from src.training.evaluator import ModelEvaluator
from src.utils.logger import get_logger
import pandas as pd

logger = get_logger(__name__)


def main():
    """å®Œæ•´å·¥ä½œæµæ¼”ç¤º"""
    
    print("\n" + "=" * 100)
    print(" è¯å“é”€é‡é¢„æµ‹ç³»ç»Ÿ - å®Œæ•´å·¥ä½œæµæ¼”ç¤º ".center(100, "="))
    print("=" * 100)
    
    try:
        # é…ç½®å‚æ•°
        GCODE = "026436"  # ä½Žé’™è…¹è†œé€æžæ¶²
        START_DATE = "2020-01-01"  # ä½¿ç”¨2020å¹´ä»¥åŽçš„æ•°æ®
        END_DATE = "2024-12-31"
        
        print(f"\nðŸ“¦ ç›®æ ‡è¯å“: {GCODE} (ä½Žé’™è…¹è†œé€æžæ¶²)")
        print(f"ðŸ“… æ•°æ®èŒƒå›´: {START_DATE} è‡³ {END_DATE}")
        
        # ==================== æ­¥éª¤ 1: æ•°æ®åŠ è½½ ====================
        print("\n" + "â”€" * 100)
        print("[æ­¥éª¤ 1/7] ðŸ“¥ æ•°æ®åŠ è½½")
        print("â”€" * 100)
        
        loader = DataLoader()
        
        # åŠ è½½è¯¥è¯å“çš„æ‰€æœ‰é”€å”®æ•°æ®ï¼ˆä¸ç”¨ start_date/end_date å‚æ•°ï¼Œé¿å… dt åˆ†åŒºåˆ—è¿‡æ»¤é—®é¢˜ï¼‰
        print(f"æ­£åœ¨ä»Žæ•°æ®åº“åŠ è½½ gcode={GCODE} çš„é”€å”®æ•°æ®...")
        df = loader.load_sales_data(
            gcode=GCODE
        )
        
        # ç”¨ pandas è¿‡æ»¤æ—¥æœŸèŒƒå›´
        print(f"è¿‡æ»¤æ—¥æœŸèŒƒå›´: {START_DATE} è‡³ {END_DATE}...")
        df = df[(df['create_dt'] >= START_DATE) & (df['create_dt'] <= END_DATE)]
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡é”€å”®è®°å½•")
        print(f"   æ—¥æœŸèŒƒå›´: {df['create_dt'].min()} è‡³ {df['create_dt'].max()}")
        print(f"   æ¶‰åŠå®¢æˆ·æ•°: {df['cust_name'].nunique()}")
        print(f"   æ€»é”€é‡: {df['qty'].sum():,.0f}")
        print(f"   å¹³å‡é”€é‡: {df['qty'].mean():.2f}")
        
        # æ˜¾ç¤ºæ•°æ®æ ·æœ¬
        print(f"\nðŸ“Š æ•°æ®æ ·æœ¬ï¼ˆå‰3æ¡ï¼‰:")
        print(df[['gcode', 'create_dt', 'qty', 'cust_name', 'gname']].head(3).to_string(index=False))
        
        if len(df) < 100:
            print(f"\nâš ï¸  è­¦å‘Š: æ•°æ®é‡ä¸è¶³ ({len(df)} æ¡)ï¼Œéœ€è¦è‡³å°‘100æ¡æ•°æ®")
            return
        
        # ==================== æ­¥éª¤ 2: é€‰æ‹©ä¸»è¦å®¢æˆ· ====================
        print("\n" + "â”€" * 100)
        print("[æ­¥éª¤ 2/7] ðŸ¥ é€‰æ‹©ä¸»è¦å®¢æˆ·")
        print("â”€" * 100)
        
        # æ‰¾å‡ºé”€å”®è®°å½•æœ€å¤šçš„å®¢æˆ·
        customer_stats = df.groupby('cust_name').agg({
            'qty': ['count', 'sum', 'mean']
        }).reset_index()
        customer_stats.columns = ['cust_name', 'record_count', 'total_qty', 'avg_qty']
        customer_stats = customer_stats.sort_values('record_count', ascending=False)
        
        print("ðŸ“ˆ é”€å”®è®°å½•æœ€å¤šçš„å‰5ä¸ªå®¢æˆ·:")
        print(customer_stats.head(5).to_string(index=False))
        
        # é€‰æ‹©è®°å½•æœ€å¤šçš„å®¢æˆ·
        CUST_NAME = customer_stats.iloc[0]['cust_name']
        print(f"\nâœ… é€‰æ‹©å®¢æˆ·: {CUST_NAME}")
        print(f"   è¯¥å®¢æˆ·çš„é”€å”®è®°å½•æ•°: {customer_stats.iloc[0]['record_count']:.0f}")
        
        # ç­›é€‰è¯¥å®¢æˆ·çš„æ•°æ®
        df_customer = df[df['cust_name'] == CUST_NAME].copy()
        print(f"   ç­›é€‰åŽæ•°æ®é‡: {len(df_customer)} æ¡")
        
        # ==================== æ­¥éª¤ 3: æ•°æ®é¢„å¤„ç† ====================
        print("\n" + "â”€" * 100)
        print("[æ­¥éª¤ 3/7] ðŸ”§ æ•°æ®é¢„å¤„ç†")
        print("â”€" * 100)
        
        processor = DataProcessor()
        
        # é‡å‘½ååˆ—ä»¥é€‚é…é¢„å¤„ç†å™¨
        df_processed = df_customer.rename(columns={
            'create_dt': 'date',
            'qty': 'sales_quantity',
            'gcode': 'drug_id',
            'cust_name': 'hospital_id'
        })
        
        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯ datetime ç±»åž‹
        df_processed['date'] = pd.to_datetime(df_processed['date'])
        df_processed = df_processed.sort_values('date').reset_index(drop=True)
        
        # æŒ‰æ—¥æœŸèšåˆæ•°æ®ï¼Œé¿å…é‡å¤çš„æ—¥æœŸæ ‡ç­¾
        print(f"ðŸ“Š æŒ‰æ—¥æœŸèšåˆé”€å”®æ•°æ®...")
        df_processed = df_processed.groupby(['date', 'drug_id', 'hospital_id']).agg({
            'sales_quantity': 'sum'  # æ±‡æ€»æ¯å¤©çš„é”€é‡
        }).reset_index()
        print(f"   èšåˆåŽæ•°æ®é‡: {len(df_processed)} æ¡ï¼ˆæ¯å¤©ä¸€æ¡ï¼‰")
        
        print(f"ðŸ“… åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®é›†...")
        df_processed = processor.create_time_series_dataset(
            df_processed,
            drug_id=GCODE,
            hospital_id=CUST_NAME,
            date_column='date',
            target_column='sales_quantity'
        )
        
        print(f"ðŸ” å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼...")
        df_processed = processor.handle_missing_values(df_processed, method='forward_fill')
        df_processed = processor.handle_outliers(
            df_processed, 
            'sales_quantity', 
            method='iqr',
            threshold=3.0
        )
        
        print(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œæ•°æ®é‡: {len(df_processed)} æ¡")
        
        # ==================== æ­¥éª¤ 4: ç‰¹å¾å·¥ç¨‹ ====================
        print("\n" + "â”€" * 100)
        print("[æ­¥éª¤ 4/7] âš™ï¸  ç‰¹å¾å·¥ç¨‹")
        print("â”€" * 100)
        
        print(f"ðŸ—ï¸  æž„å»ºæ—¶é—´åºåˆ—ç‰¹å¾...")
        feature_builder = FeatureBuilder()
        df_features = feature_builder.build_features(
            df_processed,
            target_column='sales_quantity',
            date_column='date'
        )
        
        print(f"âœ… ç‰¹å¾æž„å»ºå®Œæˆ")
        print(f"   æ€»ç‰¹å¾æ•°: {len(df_features.columns)} ä¸ª")
        print(f"   ç‰¹å¾æ•°æ®é‡: {len(df_features)} æ¡")
        
        # èŽ·å–ç‰¹å¾åˆ—ï¼ˆæŽ’é™¤ç›®æ ‡åˆ—ã€æ—¥æœŸåˆ—ã€æ ‡è¯†åˆ—ï¼Œå¹¶ä¸”åªä¿ç•™æ•°å€¼ç±»åž‹ï¼‰
        exclude_cols = ['sales_quantity', 'date', 'drug_id', 'hospital_id']
        feature_cols = [col for col in df_features.columns 
                       if col not in exclude_cols and df_features[col].dtype in ['int64', 'float64', 'int32', 'float32']]
        print(f"   å¯ç”¨äºŽå»ºæ¨¡çš„ç‰¹å¾: {len(feature_cols)} ä¸ª")
        
        if len(df_features) < 50:
            print(f"\nâš ï¸  è­¦å‘Š: ç‰¹å¾å·¥ç¨‹åŽæ•°æ®é‡ä¸è¶³ ({len(df_features)} æ¡)")
            return
        
        # ==================== æ­¥éª¤ 5: è®­ç»ƒæ¨¡åž‹ ====================
        print("\n" + "â”€" * 100)
        print("[æ­¥éª¤ 5/7] ðŸ¤– è®­ç»ƒæ¨¡åž‹")
        print("â”€" * 100)
        
        print(f"ðŸš€ ä½¿ç”¨ LightGBM è®­ç»ƒæ¨¡åž‹...")
        model = LightGBMModel()
        trainer = ModelTrainer(model, experiment_name="demo_026436")
        
        # è®­ç»ƒæ¨¡åž‹
        trained_model, test_metrics = trainer.train_on_full_data(
            df_features,
            target_column='sales_quantity',
            test_size=0.2,
            log_mlflow=False
        )
        
        print(f"âœ… æ¨¡åž‹è®­ç»ƒå®Œæˆï¼")
        print(f"\nðŸ“Š æ¨¡åž‹æ€§èƒ½æŒ‡æ ‡:")
        print(f"   RMSE (å‡æ–¹æ ¹è¯¯å·®):  {test_metrics['rmse']:.2f}")
        print(f"   MAE (å¹³å‡ç»å¯¹è¯¯å·®):  {test_metrics['mae']:.2f}")
        print(f"   MAPE (å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®): {test_metrics['mape']:.2f}%")
        print(f"   RÂ² (å†³å®šç³»æ•°):      {test_metrics['r2']:.4f}")
        
        # ==================== æ­¥éª¤ 6: æ¨¡åž‹è¯„ä¼° ====================
        print("\n" + "â”€" * 100)
        print("[æ­¥éª¤ 6/7] ðŸ“ˆ æ¨¡åž‹è¯„ä¼°")
        print("â”€" * 100)
        
        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        split_idx = int(len(df_features) * 0.8)
        test_df = df_features.iloc[split_idx:]
        
        X_test = test_df[feature_cols]
        y_test = test_df['sales_quantity']
        
        print(f"ðŸ” åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹...")
        y_pred = trained_model.predict(X_test)
        
        evaluator = ModelEvaluator()
        metrics = evaluator.evaluate(y_test.values, y_pred, return_details=True)
        
        print(f"âœ… è¯„ä¼°å®Œæˆ")
        print(f"\nðŸ“Š è¯¦ç»†è¯„ä¼°æŒ‡æ ‡:")
        for metric_name, metric_value in metrics.items():
            print(f"   {metric_name.upper():20s}: {metric_value:.4f}")
        
        # æ˜¾ç¤ºé¢„æµ‹æ ·æœ¬
        print(f"\nðŸŽ¯ é¢„æµ‹æ ·æœ¬å¯¹æ¯”ï¼ˆæœ€åŽ5æ¡ï¼‰:")
        comparison_df = pd.DataFrame({
            'å®žé™…å€¼': y_test.tail(5).values,
            'é¢„æµ‹å€¼': y_pred[-5:],
            'è¯¯å·®': y_test.tail(5).values - y_pred[-5:]
        })
        print(comparison_df.to_string(index=False))
        
        # ==================== æ­¥éª¤ 7: ç‰¹å¾é‡è¦æ€§ ====================
        print("\n" + "â”€" * 100)
        print("[æ­¥éª¤ 7/7] ðŸ” ç‰¹å¾é‡è¦æ€§åˆ†æž")
        print("â”€" * 100)
        
        importance_df = trained_model.get_feature_importance()
        
        print(f"âœ… Top 10 æœ€é‡è¦ç‰¹å¾:")
        for idx, row in importance_df.head(10).iterrows():
            bar_length = int(row['importance'] / importance_df['importance'].max() * 30)
            bar = "â–ˆ" * bar_length
            print(f"   {idx+1:2d}. {row['feature']:30s} {bar} {row['importance']:.0f}")
        
        # ==================== ä¿å­˜æ¨¡åž‹ ====================
        print("\n" + "â”€" * 100)
        print("[å¯é€‰] ðŸ’¾ ä¿å­˜æ¨¡åž‹")
        print("â”€" * 100)
        
        model_dir = Path("models")
        model_dir.mkdir(parents=True, exist_ok=True)
        model_path = model_dir / f"demo_{GCODE}_{CUST_NAME[:20].replace('/', '_')}.txt"
        
        trained_model.save(str(model_path))
        print(f"âœ… æ¨¡åž‹å·²ä¿å­˜åˆ°: {model_path}")
        
        # ==================== å®Œæˆ ====================
        print("\n" + "=" * 100)
        print(" âœ… å®Œæ•´å·¥ä½œæµæ¼”ç¤ºæˆåŠŸå®Œæˆï¼".center(100, "="))
        print("=" * 100)
        
        print(f"\nðŸ“Š æ€»ç»“ç»Ÿè®¡:")
        print(f"   è¯å“ç¼–ç :      {GCODE}")
        print(f"   å®¢æˆ·åç§°:      {CUST_NAME}")
        print(f"   è®­ç»ƒæ•°æ®é‡:    {len(df_features)} æ¡")
        print(f"   ç‰¹å¾æ•°é‡:      {len(feature_cols)} ä¸ª")
        print(f"   æ¨¡åž‹æ€§èƒ½:      RMSE={test_metrics['rmse']:.2f}, RÂ²={test_metrics['r2']:.4f}")
        print(f"   æ¨¡åž‹æ–‡ä»¶:      {model_path}")
        
        print(f"\nðŸŽ¯ æ‚¨å·²äº†è§£å®Œæ•´å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬:")
        print(f"   âœ“ æ­¥éª¤1: ä»Žæ•°æ®åº“åŠ è½½é”€å”®æ•°æ®")
        print(f"   âœ“ æ­¥éª¤2: é€‰æ‹©ä¸»è¦å®¢æˆ·è¿›è¡Œåˆ†æž")
        print(f"   âœ“ æ­¥éª¤3: æ•°æ®é¢„å¤„ç†ï¼ˆæ—¶é—´åºåˆ—ã€ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ï¼‰")
        print(f"   âœ“ æ­¥éª¤4: ç‰¹å¾å·¥ç¨‹ï¼ˆæž„å»ºæ—¶é—´åºåˆ—ç‰¹å¾ï¼‰")
        print(f"   âœ“ æ­¥éª¤5: è®­ç»ƒ LightGBM æ¨¡åž‹")
        print(f"   âœ“ æ­¥éª¤6: æ¨¡åž‹è¯„ä¼°å’Œé¢„æµ‹")
        print(f"   âœ“ æ­¥éª¤7: ç‰¹å¾é‡è¦æ€§åˆ†æž")
        
        print(f"\nðŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print(f"   1. å°è¯•å…¶ä»–è¯å“å’Œå®¢æˆ·ç»„åˆ")
        print(f"   2. è°ƒæ•´æ¨¡åž‹è¶…å‚æ•°ä¼˜åŒ–æ€§èƒ½")
        print(f"   3. ä½¿ç”¨æ›´é•¿çš„åŽ†å²æ•°æ®è¿›è¡Œè®­ç»ƒ")
        print(f"   4. æ‰¹é‡è®­ç»ƒå¤šä¸ªè¯å“-å®¢æˆ·ç»„åˆ")
        print(f"   5. å¯åŠ¨ API æœåŠ¡è¿›è¡Œåœ¨çº¿é¢„æµ‹")
        
    except Exception as e:
        logger.error(f"å·¥ä½œæµè¿è¡Œå¤±è´¥: {e}", exc_info=True)
        print(f"\nâŒ é”™è¯¯: {e}")
        print(f"\nè¯·æ£€æŸ¥:")
        print(f"  1. æ•°æ®åº“è¿žæŽ¥æ˜¯å¦æ­£å¸¸")
        print(f"  2. æ•°æ®æ˜¯å¦å……è¶³")
        print(f"  3. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: logs/app.log")
        sys.exit(1)


if __name__ == "__main__":
    main()
