"""
å±•ç¤ºæ•°æ®åº“å­—æ®µã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹å‚æ•°çš„å®Œæ•´ç¤ºä¾‹
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

from src.data.loader import DataLoader
from src.data.processor import DataProcessor
from src.features.builder import FeatureBuilder
from src.models.lgb_model import LightGBMModel
from src.utils.logger import get_logger
import pandas as pd
import numpy as np

logger = get_logger(__name__)

def show_database_schema():
    """å±•ç¤ºæ•°æ®åº“åŸå§‹å­—æ®µ"""
    print("\n" + "=" * 100)
    print(" 1ï¸âƒ£  æ•°æ®åº“åŸå§‹å­—æ®µ ".center(100, "="))
    print("=" * 100)
    
    loader = DataLoader()
    
    # åŠ è½½å°‘é‡æ•°æ®æŸ¥çœ‹ç»“æ„
    print("\nğŸ“‹ ä» StarRocks åŠ è½½çš„åŸå§‹æ•°æ®å­—æ®µ:")
    df = loader.load_sales_data(gcode="026436", limit=5)
    
    print(f"\næ•°æ®è¡¨: datasense_dlink_erpservice.view_dws_erp_sal_detail_df")
    print(f"æ€»åˆ—æ•°: {len(df.columns)}")
    print("\nå­—æ®µåˆ—è¡¨åŠæ•°æ®ç±»å‹:")
    print("-" * 100)
    
    for i, col in enumerate(df.columns, 1):
        dtype = df[col].dtype
        sample = df[col].iloc[0] if len(df) > 0 else "N/A"
        print(f"  {i:2d}. {col:30s} | ç±»å‹: {str(dtype):10s} | ç¤ºä¾‹: {sample}")
    
    print("\nğŸ“Š æ•°æ®æ ·æœ¬ï¼ˆå‰3æ¡ï¼‰:")
    print("-" * 100)
    print(df[['gcode', 'create_dt', 'qty', 'invoice_price', 'cust_name', 'gname']].head(3).to_string(index=False))
    
    print("\nğŸ’¡ å…³é”®å­—æ®µè¯´æ˜:")
    print("  â€¢ gcode: è¯å“ç¼–ç ï¼ˆç”¨äºç­›é€‰ç‰¹å®šè¯å“ï¼‰")
    print("  â€¢ create_dt: é”€å”®æ—¥æœŸï¼ˆæ—¶é—´åºåˆ—çš„å…³é”®å­—æ®µï¼‰")
    print("  â€¢ qty: é”€å”®æ•°é‡ï¼ˆé¢„æµ‹ç›®æ ‡ï¼‰")
    print("  â€¢ cust_name: å®¢æˆ·åç§°ï¼ˆç”¨äºåŒºåˆ†ä¸åŒåŒ»é™¢/å®¢æˆ·ï¼‰")
    print("  â€¢ invoice_price: å¼€ç¥¨ä»·æ ¼")
    print("  â€¢ gname: è¯å“åç§°")
    
    return df


def show_feature_engineering(df):
    """å±•ç¤ºç‰¹å¾å·¥ç¨‹è¿‡ç¨‹"""
    print("\n" + "=" * 100)
    print(" 2ï¸âƒ£  ç‰¹å¾å·¥ç¨‹è¯¦è§£ ".center(100, "="))
    print("=" * 100)
    
    # å‡†å¤‡æ•°æ®
    top_customer = df.groupby('cust_name').size().idxmax()
    df = df[df['cust_name'] == top_customer]
    
    # é‡å‘½åå’Œèšåˆ
    df_proc = df.rename(columns={
        'create_dt': 'date',
        'qty': 'sales_quantity',
        'gcode': 'drug_id',
        'cust_name': 'hospital_id'
    })
    df_proc['date'] = pd.to_datetime(df_proc['date'])
    df_proc = df_proc.groupby(['date', 'drug_id', 'hospital_id']).agg({
        'sales_quantity': 'sum'
    }).reset_index().sort_values('date')
    
    # æ•°æ®é¢„å¤„ç†
    processor = DataProcessor()
    df_proc = processor.create_time_series_dataset(
        df_proc, drug_id="026436", hospital_id=top_customer,
        date_column='date', target_column='sales_quantity'
    )
    df_proc = processor.handle_missing_values(df_proc, method='forward_fill')
    df_proc = processor.handle_outliers(df_proc, 'sales_quantity', method='iqr')
    
    print(f"\nğŸ“ é¢„å¤„ç†åçš„æ•°æ®:")
    print(f"  â€¢ æ•°æ®é‡: {len(df_proc)} æ¡ï¼ˆæŒ‰å¤©èšåˆåï¼‰")
    print(f"  â€¢ æ—¥æœŸèŒƒå›´: {df_proc['date'].min()} è‡³ {df_proc['date'].max()}")
    print(f"  â€¢ ç›®æ ‡å˜é‡ç»Ÿè®¡:")
    print(f"    - æœ€å°å€¼: {df_proc['sales_quantity'].min():.0f}")
    print(f"    - æœ€å¤§å€¼: {df_proc['sales_quantity'].max():.0f}")
    print(f"    - å¹³å‡å€¼: {df_proc['sales_quantity'].mean():.2f}")
    print(f"    - æ ‡å‡†å·®: {df_proc['sales_quantity'].std():.2f}")
    
    # ç‰¹å¾å·¥ç¨‹
    print("\nğŸ”§ å¼€å§‹ç‰¹å¾å·¥ç¨‹...")
    feature_builder = FeatureBuilder()
    df_features = feature_builder.build_features(
        df_proc, target_column='sales_quantity', date_column='date'
    )
    
    print(f"\nâœ… ç‰¹å¾æ„å»ºå®Œæˆï¼")
    print(f"  â€¢ æ€»ç‰¹å¾æ•°: {len(df_features.columns)} åˆ—")
    print(f"  â€¢ æ•°æ®é‡: {len(df_features)} æ¡")
    
    # æŒ‰ç±»åˆ«å±•ç¤ºç‰¹å¾
    print("\nğŸ“Š ç‰¹å¾åˆ†ç±»è¯¦è§£:")
    print("-" * 100)
    
    # 1. æ—¥æœŸç‰¹å¾
    date_features = [col for col in df_features.columns if any(x in col for x in ['year', 'month', 'day', 'dayofweek', 'quarter', 'sin', 'cos'])]
    print(f"\n1ï¸âƒ£  æ—¥æœŸç‰¹å¾ ({len(date_features)} ä¸ª):")
    for feat in date_features:
        print(f"  â€¢ {feat}")
    
    # 2. æ»åç‰¹å¾
    lag_features = [col for col in df_features.columns if 'lag' in col]
    print(f"\n2ï¸âƒ£  æ»åç‰¹å¾ ({len(lag_features)} ä¸ª) - å†å²é”€é‡:")
    for feat in lag_features:
        print(f"  â€¢ {feat}")
    
    # 3. æ»šåŠ¨çª—å£ç‰¹å¾
    rolling_features = [col for col in df_features.columns if 'rolling' in col]
    print(f"\n3ï¸âƒ£  æ»šåŠ¨çª—å£ç‰¹å¾ ({len(rolling_features)} ä¸ª) - ç»Ÿè®¡ç‰¹å¾:")
    for feat in rolling_features[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
        print(f"  â€¢ {feat}")
    if len(rolling_features) > 10:
        print(f"  â€¢ ... è¿˜æœ‰ {len(rolling_features) - 10} ä¸ª")
    
    # 4. å·®åˆ†ç‰¹å¾
    diff_features = [col for col in df_features.columns if 'diff' in col]
    print(f"\n4ï¸âƒ£  å·®åˆ†ç‰¹å¾ ({len(diff_features)} ä¸ª) - å˜åŒ–ç‡:")
    for feat in diff_features:
        print(f"  â€¢ {feat}")
    
    # 5. ç»Ÿè®¡ç‰¹å¾
    stat_features = [col for col in df_features.columns if 'cumsum' in col or 'cummean' in col or 'cumstd' in col]
    print(f"\n5ï¸âƒ£  ç»Ÿè®¡ç‰¹å¾ ({len(stat_features)} ä¸ª) - ç´¯è®¡ç»Ÿè®¡:")
    for feat in stat_features:
        print(f"  â€¢ {feat}")
    
    # æ˜¾ç¤ºç‰¹å¾æ•°æ®æ ·æœ¬
    print("\nğŸ“ˆ ç‰¹å¾æ•°æ®æ ·æœ¬ï¼ˆæœ€å3æ¡ï¼‰:")
    print("-" * 100)
    display_cols = ['date', 'sales_quantity', 'sales_quantity_lag_1', 'sales_quantity_rolling_7_mean', 
                    'sales_quantity_diff_1', 'dayofweek']
    print(df_features[display_cols].tail(3).to_string(index=False))
    
    return df_features


def show_model_params():
    """å±•ç¤ºæ¨¡å‹å‚æ•°"""
    print("\n" + "=" * 100)
    print(" 3ï¸âƒ£  æ¨¡å‹å‚æ•°è¯¦è§£ ".center(100, "="))
    print("=" * 100)
    
    print("\nğŸ¤– LightGBM æ¨¡å‹é»˜è®¤å‚æ•°:")
    print("-" * 100)
    
    model = LightGBMModel()
    params = model.model_params
    
    print("\næ ¸å¿ƒå‚æ•°:")
    for key, value in params.items():
        description = get_param_description(key)
        print(f"  â€¢ {key:25s} = {str(value):10s}  # {description}")
    
    print("\n\nğŸ“– å‚æ•°è¯´æ˜:")
    print("-" * 100)
    print("""
1. n_estimators (100)
   - å«ä¹‰: æ ‘çš„æ•°é‡
   - å½±å“: è¶Šå¤šè¶Šå¤æ‚ï¼Œä½†å¯èƒ½è¿‡æ‹Ÿåˆ
   - å»ºè®®: 50-500

2. max_depth (6)
   - å«ä¹‰: æ ‘çš„æœ€å¤§æ·±åº¦
   - å½±å“: è¶Šæ·±æ¨¡å‹è¶Šå¤æ‚
   - å»ºè®®: 3-10

3. learning_rate (0.1)
   - å«ä¹‰: å­¦ä¹ ç‡
   - å½±å“: è¶Šå°éœ€è¦æ›´å¤šæ ‘ï¼Œä½†æ›´ç¨³å®š
   - å»ºè®®: 0.01-0.3

4. num_leaves (31)
   - å«ä¹‰: å¶å­èŠ‚ç‚¹æ•°é‡
   - å½±å“: æ§åˆ¶æ¨¡å‹å¤æ‚åº¦
   - å»ºè®®: 20-100

5. min_child_samples (20)
   - å«ä¹‰: å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
   - å½±å“: é˜²æ­¢è¿‡æ‹Ÿåˆ
   - å»ºè®®: 10-100

6. subsample (0.8)
   - å«ä¹‰: æ¯æ¬¡è¿­ä»£ä½¿ç”¨çš„æ•°æ®æ¯”ä¾‹
   - å½±å“: é˜²æ­¢è¿‡æ‹Ÿåˆ
   - å»ºè®®: 0.6-1.0

7. colsample_bytree (0.8)
   - å«ä¹‰: æ¯æ£µæ ‘ä½¿ç”¨çš„ç‰¹å¾æ¯”ä¾‹
   - å½±å“: é˜²æ­¢è¿‡æ‹Ÿåˆ
   - å»ºè®®: 0.6-1.0
    """)
    
    return params


def get_param_description(param_name):
    """è·å–å‚æ•°æè¿°"""
    descriptions = {
        'objective': 'ç›®æ ‡å‡½æ•°ï¼ˆå›å½’ä»»åŠ¡ï¼‰',
        'metric': 'è¯„ä¼°æŒ‡æ ‡',
        'n_estimators': 'æ ‘çš„æ•°é‡',
        'max_depth': 'æ ‘çš„æœ€å¤§æ·±åº¦',
        'learning_rate': 'å­¦ä¹ ç‡',
        'num_leaves': 'å¶å­èŠ‚ç‚¹æ•°',
        'min_child_samples': 'å¶å­æœ€å°æ ·æœ¬æ•°',
        'subsample': 'æ•°æ®é‡‡æ ·æ¯”ä¾‹',
        'colsample_bytree': 'ç‰¹å¾é‡‡æ ·æ¯”ä¾‹',
        'random_state': 'éšæœºç§å­',
        'n_jobs': 'å¹¶è¡Œçº¿ç¨‹æ•°',
        'verbose': 'æ˜¯å¦æ‰“å°è®­ç»ƒæ—¥å¿—'
    }
    return descriptions.get(param_name, 'å…¶ä»–å‚æ•°')


def show_hyperparameter_tuning():
    """å±•ç¤ºè¶…å‚æ•°è°ƒä¼˜æ–¹æ³•"""
    print("\n" + "=" * 100)
    print(" 4ï¸âƒ£  è¶…å‚æ•°è°ƒä¼˜æ–¹æ³• ".center(100, "="))
    print("=" * 100)
    
    print("\nğŸ“š æ–¹æ³•ä¸€ï¼šç½‘æ ¼æœç´¢ (Grid Search)")
    print("-" * 100)
    print("""
from sklearn.model_selection import GridSearchCV

# å®šä¹‰å‚æ•°ç½‘æ ¼
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 6, 9],
    'learning_rate': [0.01, 0.1, 0.3],
    'num_leaves': [20, 31, 50]
}

# ç½‘æ ¼æœç´¢
model = LightGBMModel()
grid_search = GridSearchCV(
    model.model,
    param_grid,
    cv=5,
    scoring='neg_mean_squared_error',
    n_jobs=-1
)
grid_search.fit(X_train, y_train)

print("æœ€ä½³å‚æ•°:", grid_search.best_params_)
print("æœ€ä½³å¾—åˆ†:", -grid_search.best_score_)
    """)
    
    print("\nğŸ“š æ–¹æ³•äºŒï¼šéšæœºæœç´¢ (Random Search)")
    print("-" * 100)
    print("""
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# å®šä¹‰å‚æ•°åˆ†å¸ƒ
param_distributions = {
    'n_estimators': randint(50, 500),
    'max_depth': randint(3, 10),
    'learning_rate': uniform(0.01, 0.3),
    'num_leaves': randint(20, 100),
    'min_child_samples': randint(10, 100)
}

# éšæœºæœç´¢
random_search = RandomizedSearchCV(
    model.model,
    param_distributions,
    n_iter=50,  # å°è¯•50æ¬¡éšæœºç»„åˆ
    cv=5,
    scoring='neg_mean_squared_error',
    n_jobs=-1
)
random_search.fit(X_train, y_train)
    """)
    
    print("\nğŸ“š æ–¹æ³•ä¸‰ï¼šOptuna è´å¶æ–¯ä¼˜åŒ– (æ¨è)")
    print("-" * 100)
    print("""
import optuna
from src.optimization.hyperparameter_optimizer import HyperparameterOptimizer

# å®šä¹‰æœç´¢ç©ºé—´
search_space = {
    'n_estimators': ('int', 50, 500),
    'max_depth': ('int', 3, 10),
    'learning_rate': ('float', 0.01, 0.3),
    'num_leaves': ('int', 20, 100),
    'min_child_samples': ('int', 10, 100),
    'subsample': ('float', 0.6, 1.0),
    'colsample_bytree': ('float', 0.6, 1.0)
}

# åˆ›å»ºä¼˜åŒ–å™¨
optimizer = HyperparameterOptimizer(
    model=LightGBMModel(),
    search_space=search_space
)

# è¿è¡Œä¼˜åŒ–
best_params = optimizer.optimize(
    X_train, y_train,
    n_trials=100,  # å°è¯•100æ¬¡
    cv=5
)

print("æœ€ä½³å‚æ•°:", best_params)
    """)
    
    print("\nğŸ’¡ å®ç”¨è„šæœ¬ç¤ºä¾‹:")
    print("-" * 100)
    print("""
# ä¿å­˜ä¸º: scripts/tune_hyperparameters.py

python scripts/tune_hyperparameters.py \\
    --gcode 026436 \\
    --method optuna \\
    --n-trials 100 \\
    --output models/best_params_026436.json
    """)


def show_batch_training():
    """å±•ç¤ºæ‰¹é‡å»ºæ¨¡æ–¹æ³•"""
    print("\n" + "=" * 100)
    print(" 5ï¸âƒ£  æ‰¹é‡å»ºæ¨¡æ–¹æ³• ".center(100, "="))
    print("=" * 100)
    
    print("\nğŸ“š æ–¹æ³•ä¸€ï¼šç®€å•å¾ªç¯æ‰¹é‡è®­ç»ƒ")
    print("-" * 100)
    print("""
from src.data.loader import DataLoader
from src.training.trainer import ModelTrainer
from src.models.lgb_model import LightGBMModel

loader = DataLoader()

# è·å–æ‰€æœ‰è¯å“-å®¢æˆ·ç»„åˆ
gcodes = ['026436', '026437', '026438']  # è¯å“åˆ—è¡¨
customers = ['æŸ³å·å¸‚å·¥äººåŒ»é™¢', 'æ¡‚æ—åŒ»å­¦é™¢é™„å±åŒ»é™¢']  # å®¢æˆ·åˆ—è¡¨

results = []

for gcode in gcodes:
    for customer in customers:
        try:
            print(f"è®­ç»ƒ: {gcode} - {customer}")
            
            # åŠ è½½æ•°æ®
            df = loader.load_sales_data(gcode=gcode)
            df = df[df['cust_name'] == customer]
            
            if len(df) < 100:
                print(f"  è·³è¿‡: æ•°æ®ä¸è¶³")
                continue
            
            # è®­ç»ƒæ¨¡å‹
            model = LightGBMModel()
            trainer = ModelTrainer(model, experiment_name=f"{gcode}_{customer}")
            
            # ... ç‰¹å¾å·¥ç¨‹å’Œè®­ç»ƒ ...
            
            # ä¿å­˜æ¨¡å‹
            model_path = f"models/{gcode}_{customer}.txt"
            model.save(model_path)
            
            results.append({
                'gcode': gcode,
                'customer': customer,
                'model_path': model_path,
                'status': 'success'
            })
            
        except Exception as e:
            print(f"  å¤±è´¥: {e}")
            results.append({
                'gcode': gcode,
                'customer': customer,
                'status': 'failed',
                'error': str(e)
            })

# ä¿å­˜ç»“æœ
import pandas as pd
pd.DataFrame(results).to_csv('batch_training_results.csv', index=False)
    """)
    
    print("\nğŸ“š æ–¹æ³•äºŒï¼šä½¿ç”¨é…ç½®æ–‡ä»¶æ‰¹é‡è®­ç»ƒ")
    print("-" * 100)
    print("""
# åˆ›å»ºé…ç½®æ–‡ä»¶: config/batch_config.yaml

batch_training:
  # ä»æ•°æ®åº“è‡ªåŠ¨ç­›é€‰
  auto_select:
    enabled: true
    min_records: 500  # æœ€å°‘è®°å½•æ•°
    top_n_products: 20  # å‰Nä¸ªè¯å“
    top_n_customers: 10  # æ¯ä¸ªè¯å“çš„å‰Nä¸ªå®¢æˆ·
  
  # æˆ–æ‰‹åŠ¨æŒ‡å®š
  manual_list:
    - gcode: "026436"
      customers: ["æŸ³å·å¸‚å·¥äººåŒ»é™¢", "æ¡‚æ—åŒ»å­¦é™¢é™„å±åŒ»é™¢"]
    - gcode: "026437"
      customers: ["å¹¿è¥¿å£®æ—è‡ªæ²»åŒºäººæ°‘åŒ»é™¢"]
  
  # è®­ç»ƒå‚æ•°
  training:
    test_size: 0.2
    model_type: "lightgbm"
    use_optuna: true
    n_trials: 50
  
  # è¾“å‡ºè®¾ç½®
  output:
    model_dir: "models/batch"
    log_dir: "logs/batch"
    report_file: "reports/batch_training_report.html"

# è¿è¡Œæ‰¹é‡è®­ç»ƒ
python scripts/batch_train.py --config config/batch_config.yaml
    """)
    
    print("\nğŸ“š æ–¹æ³•ä¸‰ï¼šå¹¶è¡Œæ‰¹é‡è®­ç»ƒï¼ˆæ¨èï¼‰")
    print("-" * 100)
    print("""
from concurrent.futures import ProcessPoolExecutor, as_completed
from functools import partial

def train_single_model(gcode, customer, config):
    '''è®­ç»ƒå•ä¸ªæ¨¡å‹'''
    try:
        # ... è®­ç»ƒé€»è¾‘ ...
        return {'gcode': gcode, 'customer': customer, 'status': 'success'}
    except Exception as e:
        return {'gcode': gcode, 'customer': customer, 'status': 'failed', 'error': str(e)}

# å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
tasks = [
    ('026436', 'æŸ³å·å¸‚å·¥äººåŒ»é™¢'),
    ('026436', 'æ¡‚æ—åŒ»å­¦é™¢é™„å±åŒ»é™¢'),
    ('026437', 'å¹¿è¥¿å£®æ—è‡ªæ²»åŒºäººæ°‘åŒ»é™¢'),
    # ... æ›´å¤šç»„åˆ
]

# å¹¶è¡Œè®­ç»ƒ
results = []
with ProcessPoolExecutor(max_workers=4) as executor:
    # æäº¤æ‰€æœ‰ä»»åŠ¡
    future_to_task = {
        executor.submit(train_single_model, gcode, customer, config): (gcode, customer)
        for gcode, customer in tasks
    }
    
    # æ”¶é›†ç»“æœ
    for future in as_completed(future_to_task):
        gcode, customer = future_to_task[future]
        try:
            result = future.result()
            results.append(result)
            print(f"å®Œæˆ: {gcode} - {customer}")
        except Exception as e:
            print(f"å¤±è´¥: {gcode} - {customer}: {e}")

print(f"\\næ€»è®¡: {len(results)} ä¸ªæ¨¡å‹è®­ç»ƒå®Œæˆ")
    """)
    
    print("\nğŸ’¡ å®ç”¨è„šæœ¬ç¤ºä¾‹:")
    print("-" * 100)
    print("""
# 1. è‡ªåŠ¨æ‰¹é‡è®­ç»ƒï¼ˆæ¨èï¼‰
python scripts/batch_train.py \\
    --auto \\
    --min-records 500 \\
    --top-products 20 \\
    --top-customers 10 \\
    --parallel 4

# 2. ä»æ–‡ä»¶æ‰¹é‡è®­ç»ƒ
python scripts/batch_train.py \\
    --input config/product_customer_list.csv \\
    --parallel 4 \\
    --output-dir models/batch

# 3. æ‰¹é‡é¢„æµ‹
python scripts/batch_predict.py \\
    --model-dir models/batch \\
    --forecast-days 30 \\
    --output results/batch_forecast.csv
    """)


def main():
    """ä¸»å‡½æ•°"""
    try:
        # 1. å±•ç¤ºæ•°æ®åº“å­—æ®µ
        df = show_database_schema()
        
        # 2. å±•ç¤ºç‰¹å¾å·¥ç¨‹
        df_features = show_feature_engineering(df)
        
        # 3. å±•ç¤ºæ¨¡å‹å‚æ•°
        show_model_params()
        
        # 4. å±•ç¤ºè¶…å‚æ•°è°ƒä¼˜
        show_hyperparameter_tuning()
        
        # 5. å±•ç¤ºæ‰¹é‡å»ºæ¨¡
        show_batch_training()
        
        print("\n" + "=" * 100)
        print(" âœ… æ‰€æœ‰å†…å®¹å±•ç¤ºå®Œæˆï¼".center(100, "="))
        print("=" * 100)
        
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("  1. æŸ¥çœ‹æœ¬è„šæœ¬ç”Ÿæˆçš„è¯¦ç»†è¯´æ˜")
        print("  2. å°è¯•è°ƒæ•´æ¨¡å‹å‚æ•°: ä¿®æ”¹ src/models/lgb_model.py")
        print("  3. è¿è¡Œè¶…å‚æ•°ä¼˜åŒ–: åˆ›å»º scripts/tune_hyperparameters.py")
        print("  4. è¿è¡Œæ‰¹é‡å»ºæ¨¡: åˆ›å»º scripts/batch_train.py")
        
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
