# ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨åœ¨ 10 åˆ†é’Ÿå†…å¿«é€Ÿä¸Šæ‰‹è¯å“é”€é‡é¢„æµ‹ç³»ç»Ÿã€‚

## ğŸ“‹ å‰ç½®è¦æ±‚

- Python 3.8+
- pip
- ï¼ˆå¯é€‰ï¼‰Docker

## ğŸ› ï¸ å®‰è£…æ­¥éª¤

### æ–¹æ³• 1ï¼šæœ¬åœ°å®‰è£…ï¼ˆæ¨èç”¨äºå¼€å‘ï¼‰

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv

# 2. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows:
.\venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### æ–¹æ³• 2ï¼šä½¿ç”¨ Docker

```bash
# 1. æ„å»ºé•œåƒ
docker-compose build

# 2. å¯åŠ¨æœåŠ¡
docker-compose up -d
```

## ğŸ“Š ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆç¤ºä¾‹æ•°æ®

```bash
python scripts/generate_sample_data.py
```

è¿™å°†åˆ›å»ºï¼š
- 10 ä¸ªè¯å“ Ã— 5 ä¸ªåŒ»é™¢ = 50 ä¸ªç»„åˆ
- 2022-01-01 åˆ° 2024-12-31 çš„é”€é‡æ•°æ®
- SQLite æ•°æ®åº“æ–‡ä»¶ï¼š`data/sales.db`

## ğŸ¯ ç¬¬äºŒæ­¥ï¼šè®­ç»ƒæ‚¨çš„ç¬¬ä¸€ä¸ªæ¨¡å‹

```bash
python scripts/train.py --drug_id D001 --hospital_id H001 --model lightgbm
```

è®­ç»ƒå®Œæˆåï¼Œæ‚¨å°†çœ‹åˆ°ï¼š
- æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨ `models/` ç›®å½•
- MLflow å®éªŒè®°å½•åœ¨ `mlruns/` ç›®å½•
- ç‰¹å¾é‡è¦æ€§æ–‡ä»¶

### æŸ¥çœ‹è®­ç»ƒæŒ‡æ ‡

```bash
# å¯åŠ¨ MLflow UI
mlflow ui --host 0.0.0.0 --port 5000
```

ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼šhttp://localhost:5000

## ğŸ”® ç¬¬ä¸‰æ­¥ï¼šè¿›è¡Œé¢„æµ‹

```bash
python scripts/predict.py \
  --model_path models/lightgbm_D001_H001_YYYYMMDD_HHMMSS.txt \
  --drug_id D001 \
  --hospital_id H001 \
  --output predictions.csv
```

## ğŸŒ ç¬¬å››æ­¥ï¼šå¯åŠ¨ API æœåŠ¡

```bash
uvicorn src.serving.api:app --host 0.0.0.0 --port 8000 --reload
```

æˆ–ä½¿ç”¨ Dockerï¼š

```bash
docker-compose up -d api
```

### è®¿é—® API æ–‡æ¡£

åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼šhttp://localhost:8000/docs

### API ä½¿ç”¨ç¤ºä¾‹

#### å¥åº·æ£€æŸ¥

```bash
curl http://localhost:8000/health
```

#### å•æ¬¡é¢„æµ‹

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "drug_id": "D001",
    "hospital_id": "H001",
    "model_path": "models/lightgbm_D001_H001_YYYYMMDD_HHMMSS.txt",
    "start_date": "2024-01-01",
    "end_date": "2024-12-31"
  }'
```

#### è·å–è¯å“åˆ—è¡¨

```bash
curl http://localhost:8000/drugs
```

#### è·å–åŒ»é™¢åˆ—è¡¨

```bash
curl http://localhost:8000/hospitals
```

## ğŸ“ˆ ç¬¬äº”æ­¥ï¼šè¶…å‚æ•°ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

```python
from src.training.optimizer import HyperparameterOptimizer
from src.data.loader import DataLoader
from src.features.builder import FeatureBuilder

# åŠ è½½æ•°æ®
loader = DataLoader()
df = loader.load_sales_data(drug_id='D001', hospital_id='H001')

# ç‰¹å¾å·¥ç¨‹
feature_builder = FeatureBuilder()
df_features = feature_builder.build_features(df)

# åˆ’åˆ†æ•°æ®
from sklearn.model_selection import train_test_split
feature_cols = [col for col in df_features.columns if col not in ['sales_quantity', 'date']]
X = df_features[feature_cols]
y = df_features['sales_quantity']
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=False)

# ä¼˜åŒ–
optimizer = HyperparameterOptimizer(n_trials=50)
best_params = optimizer.optimize_lightgbm(X_train, y_train, X_valid, y_valid)
```

## ğŸ“Š ä½¿ç”¨ Jupyter Notebook

```bash
jupyter notebook notebooks/01_data_exploration.ipynb
```

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: æ•°æ®åº“è¿æ¥é”™è¯¯

**é—®é¢˜**: `sqlalchemy.exc.OperationalError`

**è§£å†³**: 
1. æ£€æŸ¥ `config/database.yaml` é…ç½®
2. ç¡®ä¿å·²è¿è¡Œ `generate_sample_data.py` åˆ›å»ºæ•°æ®åº“
3. å¦‚æœä½¿ç”¨ MySQL/PostgreSQLï¼Œç¡®ä¿æ•°æ®åº“æœåŠ¡å·²å¯åŠ¨

### Q2: æ¨¡å‹è®­ç»ƒå¾ˆæ…¢

**è§£å†³**: 
1. å‡å°‘æ•°æ®é‡ï¼šä½¿ç”¨ `--start_date` å’Œ `--end_date` å‚æ•°
2. è°ƒæ•´æ¨¡å‹å‚æ•°ï¼šåœ¨ `config/model_config.yaml` ä¸­å‡å°‘ `num_boost_round`
3. ä½¿ç”¨æ›´å°‘çš„ç‰¹å¾ï¼šä¿®æ”¹ `config/config.yaml` ä¸­çš„ç‰¹å¾é…ç½®

### Q3: API å¯åŠ¨å¤±è´¥

**è§£å†³**: 
1. æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼š`netstat -ano | findstr :8000`
2. æ›´æ¢ç«¯å£ï¼š`uvicorn src.serving.api:app --port 8001`
3. æ£€æŸ¥æ—¥å¿—ï¼šæŸ¥çœ‹ `logs/app.log`

### Q4: å†…å­˜ä¸è¶³

**è§£å†³**: 
1. æ‰¹é‡å¤„ç†ï¼šä¸€æ¬¡å¤„ç†å°‘é‡è¯å“-åŒ»é™¢ç»„åˆ
2. ä½¿ç”¨é‡‡æ ·ï¼šåœ¨ `DataLoader` ä¸­æ·»åŠ  `limit` å‚æ•°
3. ä¼˜åŒ–ç‰¹å¾ï¼šå‡å°‘æ»åæœŸå’Œæ»šåŠ¨çª—å£æ•°é‡

## ğŸ“š ä¸‹ä¸€æ­¥

1. **æ¢ç´¢æ•°æ®**: ä½¿ç”¨ Jupyter Notebook è¿›è¡Œæ•°æ®æ¢ç´¢
2. **è°ƒæ•´ç‰¹å¾**: ä¿®æ”¹ `config/config.yaml` ä¸­çš„ç‰¹å¾é…ç½®
3. **å°è¯•ä¸åŒæ¨¡å‹**: Prophetã€XGBoostã€é›†æˆæ¨¡å‹
4. **æ‰¹é‡è®­ç»ƒ**: ä¸ºå¤šä¸ªè¯å“-åŒ»é™¢ç»„åˆè®­ç»ƒæ¨¡å‹
5. **éƒ¨ç½²ç›‘æ§**: è®¾ç½®æ•°æ®æ¼‚ç§»æ£€æµ‹å’Œè‡ªåŠ¨å†è®­ç»ƒ

## ğŸ“ è¿›é˜¶æ•™ç¨‹

### æ‰¹é‡è®­ç»ƒå¤šä¸ªæ¨¡å‹

```python
from src.data.loader import DataLoader
from src.training.trainer import ModelTrainer
from src.models.lgb_model import LightGBMModel

loader = DataLoader()
drug_ids = loader.get_unique_drugs()
hospital_ids = loader.get_unique_hospitals()

for drug_id in drug_ids[:5]:  # å‰5ä¸ªè¯å“
    for hospital_id in hospital_ids[:3]:  # å‰3ä¸ªåŒ»é™¢
        try:
            df = loader.load_sales_data(drug_id=drug_id, hospital_id=hospital_id)
            # ... ç‰¹å¾å·¥ç¨‹å’Œè®­ç»ƒ
            print(f"âœ… å®Œæˆ: {drug_id} - {hospital_id}")
        except Exception as e:
            print(f"âŒ å¤±è´¥: {drug_id} - {hospital_id}: {e}")
```

### æ•°æ®æ¼‚ç§»ç›‘æ§

```python
from src.monitoring.drift import DriftDetector

detector = DriftDetector(threshold=0.05)

# æ‹ŸåˆåŸºçº¿
detector.fit_baseline(baseline_df, columns=feature_cols)

# æ£€æµ‹æ¼‚ç§»
drift_results = detector.detect_drift(baseline_df, current_df, method='ks')

# ç”ŸæˆæŠ¥å‘Š
detector.generate_drift_report(drift_results, 'reports/drift_report.txt')
```

## ğŸ’¡ æœ€ä½³å®è·µ

1. **ç‰ˆæœ¬æ§åˆ¶**: ä½¿ç”¨ MLflow è·Ÿè¸ªæ‰€æœ‰å®éªŒ
2. **å®šæœŸè¯„ä¼°**: æ¯å‘¨æ£€æŸ¥æ¨¡å‹æ€§èƒ½
3. **æ•°æ®è´¨é‡**: å®šæœŸæ£€æŸ¥æ•°æ®å®Œæ•´æ€§å’Œå¼‚å¸¸å€¼
4. **æ–‡æ¡£è®°å½•**: è®°å½•æ¨¡å‹é…ç½®å’Œä¸šåŠ¡å†³ç­–
5. **ç›‘æ§å‘Šè­¦**: è®¾ç½®æ€§èƒ½ä¸‹é™è‡ªåŠ¨å‘Šè­¦

## ğŸ“ è·å–å¸®åŠ©

- æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ï¼š`README.md`
- æŸ¥çœ‹ API æ–‡æ¡£ï¼šhttp://localhost:8000/docs
- æŸ¥çœ‹é…ç½®è¯´æ˜ï¼š`config/` ç›®å½•ä¸‹çš„ YAML æ–‡ä»¶

---

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼** ğŸ‰
